# Copy this file to .env and fill in the values before running docker-compose

# Slack app settings
SLACK_MODE=bot
SLACK_BOT_TOKEN=
# Legacy: use SLACK_CHANNEL_ID_VIEW for the "view" (database) team; SLACK_CHANNEL_ID is supported for compatibility
SLACK_CHANNEL_ID_VIEW=
SLACK_CHANNEL_ID_DATA_ENG=
SLACK_SIGNING_SECRET=

# AWS / Bedrock
AWS_REGION=us-east-1
BEDROCK_MODEL_ID=anthropic.claude-3-5-sonnet-20240620-v1:0
# Optional if you want explicit AWS creds (otherwise use instance role / secrets manager)
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_SESSION_TOKEN=

# State storage (path on the host machine). This path will be mount-bound into the containers
# so data persists when containers are removed. Default is ./state
HOST_STATE_DIR=./state
# For Docker: STATE_DIR=/app/state
# For local dev: STATE_DIR=./state (or leave as /app/state, it will fall back to /tmp)
STATE_DIR=/app/state

# Runtime behavior
RUN_MODE=job
PORT=8080

# Cron settings (used when RUN_MODE=cron)
# CRON_SCHEDULE uses standard crontab format. Default runs daily at 09:00 UTC:
CRON_SCHEDULE="0 9 * * *"
# CRON_CMD defaults to `python -m app.main` which posts the daily message
# You can customize it if you need to run a wrapper or different command
# Examples to run separate scheduled jobs:
#  - Postgres (view) coach at 09:00 UTC daily
#    CRON_CMD="python -m app.main --view"
#  - Data Engineering coach at 10:00 UTC daily
#    CRON_SCHEDULE for second job would be set in a separate cron container or your orchestrator.
CRON_CMD="python -m app.main"
# If you want two separate cron entries in your scheduler (e.g., two containers), you can set:
# CRON_CMD_VIEW="python -m app.main --view"
# CRON_CMD_DATA_ENG="python -m app.main --data-engineering"
